---
date: 2025-10-17 13.18
course: 02 Courses/Anno III/Apprendimento Automatico/Lectures
tags:
  - lecture
  - "#lab"
reviewed: false
last_reviewed:
next_review:
---
## üß† Concetti
---
#### Apprendimento Supervisionato
+ L'algoritmo impara a risolvere un compito basandosi su esempi etichettati forniti durante il training.
	+ Gli esempi sono le coppie input-output.
+ Sono anche detti task-driven.
+ _Regressione_: dobbiamo prevedere valori numerici continui.
	+ Pu√≤ essere intesa come trovare la funzione che meglio approssima la relazione tra l'input e l'output.
	+ Si rappresenta come una retta: $f(x) = xw + b$.
	+ Esempio: vogliamo prevedere il valore di una relazione.
		+ Si usa pandas per rappresentare il data set in una tabella.
			+ Possiamo vedere tutte le features.
		+ Controlliamo l'andamento delle informazioni principali del dataset con `boston.describe()`.
		+ Ora dobbiamo normalizzare i nostri dati. Per fare ci√≤ possiamo usare diverse funzioni in base alle nostre esigenze.
			+ `MinMaxScaler()`: riportiamo tutte le features in un intervallo comune che va da $0$ a $1$.
				+ Molte volte funziona bene, per√≤ dobbiamo stare attenti che nei dati non ci siano ...
			+ `MaxAbsScaler()`: riporta tutti i dati in un intervallo che va da $-1$ a $1$.
			+ `StandardScale()`: riportiamo tutti i dati con una distribuzione normale a varianza $0$.
				+ Dobbiamo stare attenti in quanto i dati possono essere asimmetrici.
			+ `LogNormalization()`: da usare se i dati sono molto asimmetrici.
		+ Costruiamo ora il nostro modello di regressione lineare.
			+ `LinearRegression()` + `fit()` per l'addestramento.
			+ `predict()` per fare una previsione sui dati.
		+ Ora bisogna valutare la bont√† del modello.
			+ Errore quadratico medio.
			+ Radice dell'errore quadratico medio.
			+ Ci sono degli intervalli per capire quanto fa cagare il modello.
+ _Classificazione_: dobbiamo prevedere valori categorici.
	+ Si deve avere un confine decisionale in cui si √® in grado di separare due classi ed associare i dati, sulla base dei loro valori, alle due diverse categorie.
	+ Balancing:
		+ Permette di gestire classi non bilanciate nei problemi di classificazione.
	+ Under-sampling: si riducono gli esempi della classe maggioritaria.
	+ Cross validation: si suddivide in data set in pi√π sottoinsiemi e nel ripetere pi√π volte l'addestramento.

## ‚ùì Domande
---

## üí° Riferimenti
---

## üß© Tasks
---
+ [ ] Review [[Lecture - 17-10-2025-13.18]]

```button 
name ‚úÖ Mark [[Lecture - 17-10-2025-13.18]] As Reviewed 
type command 
action QuickAdd: Mark As Reviewed
```
