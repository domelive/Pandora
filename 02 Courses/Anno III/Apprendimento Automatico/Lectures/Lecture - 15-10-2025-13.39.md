---
date: 2025-10-15 13.39
course: 02 Courses/Anno III/Apprendimento Automatico/Lectures
tags:
  - lecture
  - approccio_probabilistico
reviewed: false
last_reviewed:
next_review:
---
## üß† Concetti
---
#### La Distribuzione Congiunta
Si seguono i seguenti passaggi:
1. Costruire una _tabella con tutte le possibili combinazioni dei valori delle features_.
2. Stimare la _probabilita' per ogni combinazione di valori_.

Date $n$ features, _dobbiamo stimare_ $2^{n}-1$ _parametri_.

Disponendo della distribuzione congiunta, _possiamo stimare la probabilita' di qualunque evento esprimibile come combinazione logica delle features_ $$P(E)=\sum^{}_{row\in E}P(row)$$
E' altrettanto semplice _calcolare la probabilita' condizionata di un evento_ $E_{1}$ _dato un altro evento $E_{2}$_ $$P(E_{1}|E_{2})=\frac{P(E_{1}\land E_{2})}{P(E_{2})}=\frac{\sum^{}_{row \in E_{1}\land E_{2}}P(row)}{\sum^{}_{row\in E_{2}}P(row)}$$
#### Na√Øve Bayes
Suppone che $$P(X_{1},X_{2},\dots,X_{n}|Y)=\prod^{}_{i}P(X_{i}|Y)$$ovvero che, _dato $Y$_, $X_{i}$ _siano_ $X_{j}$ _indipendenti tra loro_.
#### Indipendenza Condizionale
Due eventi $X_{i}$ e $X_{j}$ sono _indipendenti dato_ $Y$ se $$P(X_{i}|X_{j},Y)=P(X_{i}|Y)$$
#### Indipendenza Condizionale In Na√Øve Bayes
$$\begin{align*} P(X_{1},X_{2}|Y) &= P(X_{1}|X_{2},Y)\cdot P(X_{2}|Y) \ \ \ \text{per Chain Rule}\\
&= P(X_{1}|Y)\cdot P(X_{2}|Y) \ \ \ \text{per indipendenza condizionale} \end{align*}$$
In generale: $$P(X_{1},X_{2},\dots,X_{n}|Y)=\prod^{}_{i}P(X_{i}|Y)$$
#### Classificazione Di Un Nuovo Dato $x^{new}=\langle x_{1},\dots,x_{n} \rangle$
$$Y^{new}=\arg \max_{y_{i}}P(Y=y_{i})\cdot \prod^{}_{j}P(X_{j}=x_{j}|Y=y_{i})$$
#### Tecnica Di Apprendimento - Stima Dei Parametri
Date variabili _aleatorie discrete_ $X_{i}, Y$:
+ ___Training___
	+ Per tutti i valori $y_{k}$ di $Y$ stimare $$\pi_{k}=P(Y=y_{k})$$
	+ Per ogni possibile valore $x_{ij}$ di $X_{i}$ stimare $$\theta_{ijk}=P(X_{i}=x_{ij}|Y=y_{k})$$
+ ___Classificazione Di Un nuovo Dato___
	+ Si calcola $$\begin{align*} Y^{new} &= \arg \max_{y_{k}}P(Y=y_{k})\cdot \prod^{}_{i}P(X_{i}=a_{i}|Y=y_{k}) \\ &= \arg \max_{x_{k}}\pi \cdot \prod^{}_{i}\theta_{ijk}\end{align*}$$supponendo che $a_{i}=x_{ij}$, cioe' che $a_{i}$ sia il $j$-esimo tra i possibili valori discreti dell'attributo $X_{i}$.
+ ___Maximum Likelihood Estimates (MLE)___
	+ $$\pi_{k}=P(Y=y_{k})=\frac{\#\mathcal{D}\{ Y=y_{k} \}}{|\mathcal{D}|}$$
	+ $$\theta_{ijk}=P(X=x_{ij}|Y=y_{k})=\frac{\#\mathcal{D}\{ X_{i}=x_{ij}\land Y=y_{k} \}}{\#\mathcal{D}\{ Y=y_{k} \}}$$
#### Natura Generativa Di Na√Øve Bayes
La regola di Bayes ci permette di _rovesciare il problema_, cercando di _stimare la distribuzione dei dati, data la categoria_. $$P(X_{1},\dots,X_{n}|Y=y_{i})$$
![[Screenshot_20251018_104730.png|center]]

Per _classificare un nuovo dato_ ci chiediamo a quale delle varie _distribuzioni dei dati che abbiamo stimato e' piu' probabile che appartenga_.
#### Riguardo La Maximum Likelihood
Come visto sopra, la MLE si calcola nel seguente modo:$$\pi_{k}=P(Y=y_{k})=\frac{\#\mathcal{D}\{ Y=y_{k} \}}{|\mathcal{D}|}$$
$$\theta_{ijk}=P(X=x_{ij}|Y=y_{k})=\frac{\#\mathcal{D}\{ X_{i}=x_{ij}\land Y=y_{k} \}}{\#\mathcal{D}\{ Y=y_{k} \}}$$
Dati _due eventi indipendenti ed equiprobabili_, possiamo definire la _distribuzione di Bernoulli_.
+ Prendiamo in esempio il lancio di una moneta.
+ Abbiamo due possibili esiti, $0$ e $1$, con probabilita' $\theta$ e $1-\theta$.
+ Sia $X^n$ il numero di $0$ in una sequenza di $n$ lanci; $X^n$ segue una _distribuzione binomiale_ $$P(X^{n}=\alpha_{0}|\theta)=\binom{n}{\alpha_{0}}\cdot \theta^{\alpha_{0}}\cdot(1-\theta)^{\alpha_{1}}$$dove $\alpha_{0}=n-\alpha_{1}$ e' il numero di $0$ nella sequenza $(\alpha_{0})+\alpha_{1}=n$.

Adesso possiamo arrivare al _calcolo effettivo di MLE_:
+ Facendo riferimento all'esempio della moneta, si parte da $$\hat{\theta}=\arg \max_{\theta}P(X^{n}=\alpha_{0}|\theta)=\arg \max_{\theta}\theta^{\alpha_{0}}\cdot(1-\theta)^{\alpha_{1}}$$
+ In modo equivalente possiamo cercare $\theta$ in modo che massimizzi il logaritmo della espressione precedente $$\ln(\theta^{\alpha_{0}}\cdot(1-\theta)^{\alpha_{1}})=\alpha_{0}\ln(\theta)+\alpha_{1}\ln(1-\theta)$$
+ Derivando rispetto a $\theta$ otteniamo $$\frac{\alpha_{0}}{\theta}-\frac{\alpha_{1}}{1-\theta}=\frac{\alpha_{0}-\alpha_{0}\theta-\alpha_{1}\theta}{\theta \cdot(1-\theta)}$$
+ Che si annulla per $$\theta=\frac{\alpha_{0}}{\alpha_{0}+\alpha_{1}}=\frac{\alpha_{0}}{n}$$
Possiamo anche avere un _caso multivalore_.
+ Ad esempio il lancio di un dado, dove ci sono $k$ possibili esiti, $\{ 1,2,\dots,k \}$ con probabilita' $\theta_{i}$ dove $\sum^{}_{i}\theta_{i}=1$.
+ Le sequenze di $n$ lanci seguono una _distribuzione multinomiale_ $$P(X^{n}=\alpha_{i}|\theta)=c_{\alpha_{i}}\prod^{}_{i}\theta_{i}^{\alpha_{i}}$$dove:
	+ $\alpha_{i}$ e' il numero di $i$ nella sequenza.
	+ $c_{\alpha_{i}}$ e' una costante combinatoria che non dipende da $\theta$.
+ Quindi nel caso multivalore, la MLE si calcola come $$\theta_{i}=\frac{\alpha_{i}}{\sum^{}_{i}\alpha_{i}}=\frac{\alpha_{i}}{n}$$

## ‚ùì Domande
---

## üí° Riferimenti
---

## üß© Tasks
---
+ [ ] Review [[Lecture - 15-10-2025-13.39]]
+ [ ] Cambiare data [[Lecture - 15-10-2025-13.39]]

```button 
name ‚úÖ Mark [[Lecture - 15-10-2025-13.39]] As Reviewed 
type command 
action QuickAdd: Mark As Reviewed
```
