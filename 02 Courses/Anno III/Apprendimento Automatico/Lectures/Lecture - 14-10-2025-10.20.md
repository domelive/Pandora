---
date: 2025-10-14 10.20
course: 02 Courses/Anno III/Apprendimento Automatico/Lectures
tags:
  - lecture
  - "#alberi_di_decisione"
reviewed: false
last_reviewed:
next_review:
---
## üß† Concetti
---
#### Approssimazione Di Funzioni
___Training Set___: insieme di _esempi di allenamento_ del tipo: $$\langle x^{(i)}, y^{(i)} \rangle$$dove:
+ $x^{(i)} \in X$ --> Insieme degli inputs.
+ $y^{(i)} \in Y$ --> Insieme degli outputs.
+ $i$ --> Indice dell'istanza dell'esempio di training.

Il nostro _obiettivo_ e' quello di _apprendere la funzione che mappa $x^{(i)}$ a $y{(i)}$_.
+ Se _$Y$ e' discreto_ allora il problema e' di _classificazione_.
	+ Predizione di una classe.
+ Se _$Y$ e' continuo_ allora il problema e' di _regressione_.
	+ Predizione di un valore.
#### Spazio Delle Ipotesi
Lo spazio delle ipotesi, _e' un insieme di funzioni $H$, all'interno del quale cercare la soluzione che meglio approssima i dati di training_.
+ Le tecniche di Machine Learning richiedono la scelta preliminare di questo spazio di funzioni.
+ Un modello e' un modo di specificare e calcolare una funzione nello spazio delle ipotesi $H$.
#### Aspetto Di Un Albero Di Decisione
![[Screenshot_20251014_105300.png]]
+ Ogni _nodo_ testa un _attributo/feature_ $X$.
+ Ogni _arco_ uscente da un nodo _corrisponde a uno dei possibili valori discreti di_ $X$.
+ Ogni _foglia predice la risposta_ $Y$, o una probabilita' $P(Y|X)$.
+ La _profondita' massima_ dell'albero sara' pari al _numero di feature_.

Per _configurare_ il problema sopra, _e arrivare all'albero di decisione_:
+ Per quanto riguarda _l'insieme degli inputs_, ogni istanza $x \in X$ e' un _vettore di features_ del seguente tipo: $$\langle \text{Humidity=high, Wind=weak, Outlook=rain, Temp=hot} \rangle$$
+ La _funzione target_ e': $$f : X \to Y$$dove $Y$ assume _valori discreti_, in quanto sono booleani.
+ Lo _spazio delle ipotesi_ $H$ e': $$H = \{h \ | \ h:X \to Y\}$$dove non vi e' alcuna restrizione.

Data la configurazione, vogliamo quindi:
+ _Modellare $h \in H$_ con un albero di decisione.
+ _Ogni istanza_ $x \in X$ _definisce un cammino nell'albero che conduce ad un foglia_ etichettata con $y \in Y$, _corrispondente alla soluzione predetta_.
#### Espressivita' Del Modello
Occorre rispondere a delle domande:
1. ___Abbiamo un albero di decisione per ogni funzione all'interno dell'insieme $H$ ?___
2. ___Se l'albero esiste, e' unico?___
	+ No, in quanto posso avere piu' alberi decisionali per la predizione della stessa classe.
3. ___Se non e' unico, abbiamo delle preferenze___?
	+ Si, in quanto possiamo scegliere il miglior attributo in base allo sbilanciamento delle predizioni precedenti.
#### Costruzione Top Down Induttiva
1. Assegnare al _nodo_ corrente il _"miglior" attributo_ $X_{i}$.
2. Creare un _nodo figlio_ per _ogni possibile valore di_ $X_{i}$ e _propagare i dati verso i figli_ a seconda del loro valore.
3. Per _ogni nodo figlio_, _se tutti i dati_ del training set associati al nodo _hanno la stessa etichetta $Y$_, _marcare il nodo come foglia con etichetta $Y$_, altrimenti ripetere dal primo punto.
#### Entropia
L'___entropia___ di una variabile aleatoria $X$ e': $$H(X) = - \sum^{n}_{i = 1}P(X = i)\log_{2}(P(X = i))$$dove $n$ e' _il numero dei possibili valori di $X$_.

Essa _misura il grado di inpurita' dell'informazione_.
+ E' _massima_ ($\log n$) quando $X$ e' _uniformemente distribuita tra tutti i suoi $n$ valori_.
+ E' _minima_ ($0$) quando $X$ e' _concentrata su un singolo valore_.
#### Teoria Dell'informazione
Ci dice che ___l'entropia e' la quantita' media di informazione prodotta da una sorgente stocastica di dati___.

_L'informazione e' associata alla probabilita' di ogni dato_, ovvero la "sorpresa" associata a quel determinato evento.
+ Un evento con _probabilita'_ $1$ _non trasmette informazione_: $$I(1) = 0$$
+ Dati _due eventi indipendenti_ con probabilita' $p_{1}$ e $p_{2}$, la _probabilita' congiunta e'_ $p_{1}p_{2}$ ma _l'informazione acquisita e' la somma delle informazioni dei due eventi indipendenti_: $$I(p_{1}p_{2}) = I(p_{1}) + I(p_{2})$$
Ci aspettiamo che _l'informazione sia anti-monotona rispetto alla probabilita'_ ed e' quindi naturale definire $$I(p) = -\log(p)$$
+ In altre parole _se la probabilita' e' bassa allora l'evento e' interessante_.
#### Teoria Dei Codici
Ci dice che ___l'entropia misura il numero medio di bits richiesti per trasmettere il valore prodotto da una sorgente stocastica $X$___.

Supponiamo di avere $n$ eventi con la stessa probabilita'. Per codificare ogni possibile risultato occorrono $\log(n)$ bits.
Calcoliamo l'entropia in questo caso: $$\begin{array}{cases} H(X) = -\sum^{n}_{i=1}P(X=i)\log(P(X=i))  \\
H(X) = -\sum^{n}_{i=1} \frac{1}{n} \log\left( \frac{1}{n} \right)  \\ 
H(X) = \log(n) \end{array}$$
_Se gli eventi non hanno la stessa probabilita' possiamo migliorare la codifica_.
#### Guadagno Informativo
+ ___Entropia Di Una Variabile Aleatoria $X$___: $$H(X) = - \sum^{n}_{i = 1}P(X = i)\log_{2}(P(X = i))$$
+ ___Entropia Condizionale Di $X$ Dato Uno Specifico $Y = v$___: $$H(X) = - \sum^{n}_{i = 1}P(X = i|Y = v)\log_{2}(P(X = i|Y = v))$$
+ ___Entropia Condizionale Di $X$ Dato $Y$___ (media ponderata sugli $m$ possibili valori di $Y$): $$H(X|Y)=\sum^{m}_{v=1}P(Y=v)H(X|Y=v)$$
+ ___Guadagno Informativo Tra $X$ E $Y$___: $$I(X,Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)$$
#### Il Caso Continuo
Quando gli attributi sono continui, _prendiamo decisioni in base ad opportune soglie_, e le _confrontiamo in base al loro guadagno informativo_.

Le soglie possono essere scelte:
+ Facendo _sampling a intervalli discreti prefissati_.
+ _Ordinando il training set rispetto a un dato attributo_ e scegliere come soglie i _valori medi tra dati consecutivi_.

## ‚ùì Domande
---

## üí° Riferimenti
---

## üß© Tasks
---
+ [ ] Review [[Lecture - 14-10-2025-10.20]]
+ [ ] Cambiare data [[Lecture - 14-10-2025-10.20]]

```button 
name ‚úÖ Mark [[Lecture - 2025-10-14-10.20]] As Reviewed 
type command 
action QuickAdd: Mark As Reviewed
```
