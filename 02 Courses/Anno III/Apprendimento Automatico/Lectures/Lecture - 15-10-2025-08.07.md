---
date: 2025-10-15 08.07
course: 02 Courses/Anno III/Apprendimento Automatico/Lectures
tags:
  - lecture
  - alberi_di_decisione
reviewed: false
last_reviewed:
next_review:
---
## üß† Concetti
---
#### Overfitting
Consideriamo _l'errore relativo_ all'ipotesi $h \in H$
+ Sul _training set_: $error_{train}(h)$.
+ Sul _data set $\mathcal{D}$_: $error_{\mathcal{D}}(h)$.

Diciamo che $h$ _overfitta il training set se esiste un'altra ipotesi_ $h^\prime$ _tale che_ $$error_{train}(h) < error_{train}(h^\prime)$$ma $$error_{\mathcal{D}}(h) > error_{\mathcal{D}}(h^\prime)$$
#### Overfitting E Complessita' Del Modello
![[Screenshot_20251015_082025.png]]
+ _Underfitting_ (zona a sinistra): il modello e' troppo semplice per apprendere i pattern dei dati.
	+ Si dice che il modello ha _high bias_ e _low variance_, ovvero non si adatta bene nemmeno ai dati che ha visto.
+ _Bias-variance trade-off_ (zona centrale): il modello e' abbastanza complesso da imparare i pattern principali, ma non cosi' tanto da memorizzarli.
	+ _L'errore di test raggiunge il suo minimo_, ottenendo cosi' la _migliore generalizzazione_.
+ _Overfitting_ (zona a destra): il modello e' troppo complesso e, oltre ai pattern reali, impara anche il rumore e le irregolarita' dei dati di training.
	+ _L'errore di training diminuisce ma l'errore di test aumenta_, in quanto il _modello non generalizza bene sui nuovi dati_.
#### Controllare Ed Evitare Overfitting
Il problema principale e' che _non conosciamo il data set_ $\mathcal{D}$.

La strategia e' quella di _dividere i dati disponibili in tre insiemi disgiunti_:
+ ___Training Set___: utilizzato per scegliere $h$.
	+ Per _addestramento_ del modello.
+ ___Validation Set___: utilizzato per misurare la precisione e l'overfitting di $h$.
	+ Per _ottimizzazione_ del modello.
+ ___Test Set___: utilizzato per la valutazione finale.
	+ Per _prestazioni_ del modello.
#### Evitare Overfitting Sugli Alberi Di Decisione
+ ___Early Stopping___: si _termina la costruzione dell'albero non appena il miglioramento del modello non e' piu' statisticamente significativo_.
	+ Ad esempio quando il [[Lecture - 14-10-2025-10.20#Guadagno Informativo|guadagno informativo]] e' inferiore ad una certa soglia.
	+ Oppure quando il numero dei dati relativo al nodo e' troppo piccolo.
+ ___Post-Pruning___: si _sviluppa l'intero albero e successivamente si procede a togliere i rami che creano overfitting_.
#### Post-Pruning Finalizzato Alla Riduzione Dell'Errore
Per prima cosa si _costruisce un albero di decisione completo per il training set_.

Successivamente si ripete la seguente operazione finch'e' un'ulteriore _pruning non migliora l'accuratezza_ della predizione:
1. Per ogni sotto-albero, _valutare_ (sul validation set) _l'impatto della sua rimozione sull'accuratezza della classificazione_.
2. Effettuare (in modo greedy) il _pruning del sotto-albero che ottimizza l'accuratezza del modello_.
#### Gini's Impurity
Il coefficiente di Gini _misura la probabilita' che un generico elemento sia mal classificato in base alla classificazione corrente_.
+ Possibile alternativa alla nozione di [[Lecture - 14-10-2025-10.20#Entropia|entropia]].

Date $m$ _categorie_, sia $f_{i}$ la _frazione dei dati con etichetta_ $i$.
+ Quest'ultima e' pari alla _probabilita' che un qualche input appartenga alla categoria_ $i$.
+ La _probabilita' che venga classificato in modo errato e; dunque_ $1 - f_{i}$.
+ Il coefficiente di Gini e' semplicemente la _media pesata di questa quantita' su tutte le possibili categorie_, cioe':
$$I_{G}(f)=\sum^{m}_{i=1}f_{i}(1-f_{i})=\sum^{m}_{i=1}(f_{i}-f_{i}^2)=\sum^{m}_{i=1}f_{i}-\sum^{m}_{i=1}f_{i}^2=1-\sum^{m}_{i=1}f_{i}^2$$
La metrica e' applicata su ogni nodo figlio, e i valori sono sommati in modo pesato allo stesso modo per l'entropia, al fine di ottenere una misura della qualita' dell'attributo.

Di sotto un esempio:
![[Screenshot_20251015_084842.png]]
#### Aspetti Degli Alberi Di Decisione
___Positivi___:
+ _Facili da capire_ date le semplici regole logiche e inoltre possono essere visualizzati.
+ _Poco processing_ e' di solito necessario.
+ _Costo predittivo basso_.
+ Puo' essere utilizzato _sia con features discrete che continue_.

___Negativi___:
+ _Rischio elevato di overfitting_.
+ _Selezione degli attributi piuttosto instabile al variare del data set_.
+ _Facile costruire alberi profondamente sbilanciati_, specialmente in presente di una classe dominante.
#### Foreste
Gli alberi di decisione sono abitualmente utilizzati come componenti delle cosiddette _Random Forests_ con una tecnica ad _ensemble_.

Le tecniche ad ensemble sfruttano il principio che un _gran numero di modelli sufficientemente scorrelati_, combinati come un comitato, _tende a fornire prestazioni predittive migliori rispetto ai singoli modelli_.
+ Se i modelli di base (weak learners) commettono errori diversi, allora combinandoli si riduce la varianza complessiva e si ottiene una migliore capacita' di generalizzazione.
+ Piu' opinioni indipendenti portano a una decisione piu' robusta.

Per garantire la _differenziazione degli alberi_:
+ ___Bagging___: allenare i modelli su _sottoinsiemi random_ (bags) _dei dati di input_.
+ ___Feature Randomness___: costruire gli alberi a partire da _sottoinsiemi random delle features_.

## ‚ùì Domande
---

## üí° Riferimenti
---
+ [[Lecture - 14-10-2025-10.20]]

## üß© Tasks
---
+ [ ] Review [[Lecture - 15-10-2025-08.07]]
+ [ ] Cambiare Data [[Lecture - 15-10-2025-08.07]]

```button 
name ‚úÖ Mark [[Lecture - 15-10-2025-08.07]] As Reviewed 
type command 
action QuickAdd: Mark As Reviewed
```
